{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "from omegaconf import OmegaConf\n",
    "from config import SciFactT5Config\n",
    "import definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Project directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'definitions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9caa6907ffcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefinitions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPROJECT_VARS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mROOT_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefinitions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPROJECT_VARS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mROOT_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'definitions' is not defined"
     ]
    }
   ],
   "source": [
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from config import SciFactT5Config\n",
    "import definitions\n",
    "sys.path.append(os.path.dirname(definitions.PROJECT_VARS.ROOT_DIR))\n",
    "print(definitions.PROJECT_VARS.ROOT_DIR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset for Scifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verisci.covid import AbstractRetriever, RationaleSelector, LabelPredictor\n",
    "from verisci.evaluate.lib.data import GoldDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_claim_label_from_jsonl(dataset_jsonl):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        dataset_jsonl (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    claim_label_list_train = []\n",
    "    for cur_claim in dataset_jsonl:\n",
    "        claim_txt = cur_claim.claim\n",
    "\n",
    "        for doc_id, evidence in cur_claim.evidence.items():\n",
    "\n",
    "            ev_doc = cur_claim.release.corpus.get_document(doc_id)\n",
    "\n",
    "            claim_label = evidence.label.name\n",
    "\n",
    "            tmp_dic = {\"claim\" : claim_txt, \"label\" : claim_label}\n",
    "\n",
    "            claim_label_list_train.append(tmp_dic)\n",
    "    return claim_label_list_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_claim_label_evidence_from_jsonl(dataset_jsonl, source):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        dataset_jsonl (_type_): _description_\n",
    "        source (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    claim_label_list_train = []\n",
    "    for cur_claim in dataset_jsonl:\n",
    "        claim_txt = cur_claim.claim\n",
    "        for doc_id, evidence in cur_claim.evidence.items():\n",
    "            ev_doc = claim_train.release.corpus.get_document(doc_id)\n",
    "            claim_label = evidence.label.name\n",
    "            list_rationales = []\n",
    "            for i, sents in enumerate(evidence.rationales):\n",
    "                list_rationales = [sent for i, sent in enumerate(ev_doc.sentences) if i in sents]\n",
    "            tmp_dic = {\"claim\" : claim_txt, \"label\" : claim_label, \"list_rationales\" :list_rationales, \"source\" :source}\n",
    "            claim_label_list_train.append(tmp_dic)\n",
    "    return claim_label_list_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SciFactT5Config(target_dataset=ScifactTargetDataset(base_dir='/home/qudratealahyratu/research/nlp/fact_checking/my_work/T5ParEvo/target_system/scifact/data', loc_target_dataset_corpus='/home/qudratealahyratu/research/nlp/fact_checking/my_work/T5ParEvo/target_system/scifact/data/corpus.jsonl', loc_target_dataset_train='/home/qudratealahyratu/research/nlp/fact_checking/my_work/T5ParEvo/target_system/scifact/data/claims_train.jsonl', loc_target_dataset_dev='/home/qudratealahyratu/research/nlp/fact_checking/my_work/T5ParEvo/target_system/scifact/data/claims_dev.jsonl'), target_model=ScifactTargetModel(base_dir='/home/qudratealahyratu/research/nlp/fact_checking/my_work/T5ParEvo/target_system/model', loc_label_model='/home/qudratealahyratu/research/nlp/fact_checking/my_work/T5ParEvo/target_system/model/label_roberta_large_fever_scifact', loc_rationale_model='/home/qudratealahyratu/research/nlp/fact_checking/my_work/T5ParEvo/target_system/model/rationale_roberta_large_fever_scifact'), paraphrasing_model=T5TunedParaphrasingModel(model_name='finetuned_paws_abstracts', tokenizer_name='Vamsi/T5_Paraphrase_Paws', model_url_or_path='/home/qudratealahyratu/research/nlp/fact_checking/my_work/T5ParEvo/models/paraphraser/t5_paws_masked_claim_abstract_paws_3_epoch_2/model_3_epochs/'), t5_generation_param=T5GenParams(max_length=512, do_sample=True, top_k=50, top_p=0.99, repetition_penalty=3.5, early_stopping=True, num_return_sequences=5), fine_tune_settings=SettingsFineTuning(paraphrase_ft_train_split=0.2, paraphrase_ft_dataset_direction=FineTuningDatasetDirection(), num_of_epoch_req_ft=10))\n",
      "Example 39: A diminished ovarian reserve does not solely indicate infertility in an a priori non-infertile population.\n",
      "\n",
      "Evidence sets:\n",
      "\n",
      "####################\n",
      "\n",
      "13497630: SUPPORTS\n",
      "Set 0:\n",
      "\t- After adjusting for age, body mass index, race, current smoking status, and recent hormonal contraceptive use, women with low AMH values (<0.7 ng/mL [n = 84]) did not have a significantly different predicted probability of conceiving by 6 cycles of attempt (65%; 95% CI, 50%-75%) compared with women (n = 579) with normal values (62%; 95% CI, 57%-66%) or by 12 cycles of attempt (84% [95% CI, 70%-91%] vs 75% [95% CI, 70%-79%], respectively).\n",
      "Set 1:\n",
      "\t- Women with high serum FSH values (>10 mIU/mL [n = 83]) did not have a significantly different predicted probability of conceiving after 6 cycles of attempt (63%; 95% CI, 50%-73%) compared with women (n = 654) with normal values (62%; 95% CI, 57%-66%) or after 12 cycles of attempt (82% [95% CI, 70%-89%] vs 75% [95% CI, 70%-78%], respectively).\n",
      "Set 2:\n",
      "\t- Women with high urinary FSH values (>11.5 mIU/mg creatinine [n = 69]) did not have a significantly different predicted probability of conceiving after 6 cycles of attempt (61%; 95% CI, 46%-74%) compared with women (n = 660) with normal values (62%; 95% CI, 58%-66%) or after 12 cycles of attempt (70% [95% CI, 54%-80%] vs 76% [95% CI, 72%-80%], respectively).\n",
      "Set 3:\n",
      "\t- Inhibin B levels (n = 737) were not associated with the probability of conceiving in a given cycle (hazard ratio per 1-pg/mL increase, 0.999; 95% CI, 0.997-1.001).\n",
      "Set 4:\n",
      "\t- Conclusions and Relevance Among women aged 30 to 44 years without a history of infertility who had been trying to conceive for 3 months or less, biomarkers indicating diminished ovarian reserve compared with normal ovarian reserve were not associated with reduced fertility.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cfg= SciFactT5Config()\n",
    "ds_train = GoldDataset(cfg.target_dataset.loc_target_dataset_corpus,\n",
    "                    cfg.target_dataset.loc_target_dataset_train)\n",
    "claim_train = ds_train.get_claim(39)\n",
    "\n",
    "dic_train = get_claim_label_evidence_from_jsonl(ds_train, source = \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Tuple, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from T5ParEvo.src.data import data as dataobj\n",
    "\n",
    "def get_datalist_from_dict_ds(data_dict : Dict):\n",
    "    counter_gold_claim = 0\n",
    "    data_list = []\n",
    "    for cur_claim in data_dict:\n",
    "        claim = dataobj.Claim(claim_text = cur_claim['claim'])\n",
    "        rationales = []\n",
    "        for cur_ratnl in cur_claim['list_rationales']:\n",
    "            rationale = dataobj.Rationale(rationale_text = cur_ratnl)\n",
    "            label_obj = dataobj.Label.get_enum_rep_label(res_str = cur_claim['label'])\n",
    "            rationales.append({'rationale': rationale, 'label': label_obj})\n",
    "        claim_org = dataobj.ClaimRationale(id = str(counter_gold_claim), claim = claim, rationales = rationales)\n",
    "        data_list.append(claim_org)    \n",
    "        counter_gold_claim += 1    \n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list_train = get_datalist_from_dict_ds(dic_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('scifact')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f28508567287f3243fa81c26f52e86f631e4a20d6b0e4ab397da90b0c5458c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
