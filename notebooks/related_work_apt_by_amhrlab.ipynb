{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module_path :  /home/qudratealahyratu/research/nlp/fact_checking/my_work/T5ParEvo\n",
      "root dir :  /home/qudratealahyratu/research/nlp/fact_checking/my_work/T5ParEvo\n",
      "definitions.PROJECT_VARS.ROOT_DIR :  /home/qudratealahyratu/research/nlp/fact_checking/my_work/T5ParEvo\n",
      "os.path.dirname(definitions.PROJECT_VARS.ROOT_DIR) :  /home/qudratealahyratu/research/nlp/fact_checking/my_work\n",
      "/home/qudratealahyratu/research/nlp/fact_checking/my_work/T5ParEvo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qudratealahyratu/anaconda3/envs/scifact/lib/python3.7/site-packages/pytorch_lightning/core/decorators.py:66: LightningDeprecationWarning: The `@auto_move_data` decorator is deprecated in v1.3 and will be removed in v1.5. Please use `trainer.predict` instead for inference. The decorator was applied to `predict`\n",
      "  \"The `@auto_move_data` decorator is deprecated in v1.3 and will be removed in v1.5.\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List,Tuple, Optional\n",
    "import json\n",
    "#\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(0,module_path)\n",
    "print('module_path : ', module_path)\n",
    "from config import SciFactT5Config\n",
    "import definitions\n",
    "sys.path.append(os.path.dirname(definitions.PROJECT_VARS.ROOT_DIR))\n",
    "print('definitions.PROJECT_VARS.ROOT_DIR : ', definitions.PROJECT_VARS.ROOT_DIR)\n",
    "print('os.path.dirname(definitions.PROJECT_VARS.ROOT_DIR) : ',os.path.dirname(definitions.PROJECT_VARS.ROOT_DIR))\n",
    "#\n",
    "\n",
    "from T5ParEvo.src.data.data import Claim, Label, ClaimPredictions,GoldDataset\n",
    "from T5ParEvo.src.linguistic.ner_abbr import NEREntity, Abbreviation\n",
    "from multivers import util\n",
    "from multivers.data_r import ClaimDataLoaderGenerator, get_dataloader, DataLoaderGenerator\n",
    "from multivers.model_r import MultiVerSModel\n",
    "\n",
    "from T5ParEvo.target_system.multivers.multivers_interface import PredictionParams, ModelPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset to be used only for training\n",
    "cfg= SciFactT5Config()\n",
    "ds_train = GoldDataset(cfg.target_dataset.loc_target_dataset_corpus,\n",
    "                    cfg.target_dataset.loc_target_dataset_train)\n",
    "claim_train = ds_train.get_claim(39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = PredictionParams(\n",
    "    checkpoint_path= \"/home/qudratealahyratu/research/nlp/fact_checking/my_work/multivers/checkpoints/scifact.ckpt\",\n",
    "    output_file= None,#\"prediction/pred_opt_scifact.jsonl\",\n",
    "    batch_size=5,\n",
    "    device=0,\n",
    "    num_workers=4,\n",
    "    no_nei=False,\n",
    "    force_rationale=False,\n",
    "    debug=False,\n",
    ")\n",
    "corpus_file = cfg.target_dataset.loc_target_dataset_corpus#cfg.target_dataset.loc_target_dataset_test#\"/home/qudratealahyratu/research/nlp/fact_checking/my_work/multivers/data/scifact/corpus.jsonl\"\n",
    "\n",
    "gold_claims = Claim.load_claims_from_file(cfg.target_dataset.loc_target_dataset_test) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-large-4096 were not used when initializing LongformerModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/qudratealahyratu/anaconda3/envs/scifact/lib/python3.7/site-packages/deprecate/deprecation.py:115: LightningDeprecationWarning: The `Metric` was deprecated since v1.3.0 in favor of `torchmetrics.metric.Metric`. It will be removed in v1.5.0.\n",
      "  stream(template_mgs % msg_args)\n",
      "100%|██████████| 594/594 [05:00<00:00,  1.98it/s]\n"
     ]
    }
   ],
   "source": [
    "#get unique claims\n",
    "unique_gold_claims = Claim.get_unique_claims(gold_claims)\n",
    "# Predict for unique claims\n",
    "dataloader_generator = DataLoaderGenerator(params, unique_gold_claims, corpus_file)\n",
    "dataloader = dataloader_generator.get_dataloader_by_claims()\n",
    "predictor = ModelPredictor(params, dataloader)\n",
    "prediction_formatted = predictor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Formatting predictions: 100%|██████████| 297/297 [00:00<00:00, 31281.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# prediction_formatted\n",
    "claim_org_predictions: List[ClaimPredictions] = []\n",
    "# format all the predictions\n",
    "for cur_prediction in tqdm(prediction_formatted, desc=\"Formatting predictions\"):\n",
    "    cur_claim = Claim.get_claim_by_id(gold_claims, cur_prediction['id'])\n",
    "    claim_predictions = ClaimPredictions.from_formatted_prediction(cur_prediction, gold_claim = cur_claim)\n",
    "    claim_org_predictions.append(claim_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10-20% of people with severe mental disorder receive no treatment in low and middle income countries.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claim_org_predictions[0].gold.claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "paraphrasing_tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "paraphrasing_model = T5ForConditionalGeneration.from_pretrained(\"coderpotter/T5-for-Adversarial-Paraphrasing\")\n",
    "\n",
    "# this function will take a sentence, top_k and top_p values based on beam search\n",
    "def generate_paraphrases(sentence, top_k=50, top_p=0.99):\n",
    "    text = \"paraphrase: \" + sentence + \" </s>\"\n",
    "    encoding = paraphrasing_tokenizer.encode_plus(text, max_length=256, padding=\"max_length\", return_tensors=\"pt\")\n",
    "    input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
    "    beam_outputs = paraphrasing_model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_masks,\n",
    "        do_sample=True,\n",
    "        max_length=256,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "        early_stopping=True,\n",
    "        num_return_sequences=10,\n",
    "    )\n",
    "    final_outputs = []\n",
    "    for beam_output in beam_outputs:\n",
    "        sent = paraphrasing_tokenizer.decode(beam_output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        if sent.lower() != sentence.lower() and sent not in final_outputs:\n",
    "            final_outputs.append(sent)\n",
    "    return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/297 [00:00<?, ?it/s]/home/qudratealahyratu/anaconda3/envs/scifact/lib/python3.7/site-packages/transformers/models/t5/tokenization_t5.py:195: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  f\"This sequence already has {self.eos_token}. In future versions this behavior may lead to duplicated eos tokens being added.\"\n",
      "100%|██████████| 297/297 [03:26<00:00,  1.43it/s]\n"
     ]
    }
   ],
   "source": [
    "paraphrase_claims = []\n",
    "for cur_claim in tqdm(claim_org_predictions):\n",
    "    paraphrases = generate_paraphrases(cur_claim.gold.claim)\n",
    "    cur_claim_paraphrased = {}\n",
    "    cur_claim_paraphrased['claim'] = cur_claim.gold.claim\n",
    "    cur_claim_paraphrased['paraphrases'] = paraphrases\n",
    "    paraphrase_claims.append(cur_claim_paraphrased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claim': 'Autologous transplantation of mesenchymal stem cells has worse graft function than induction therapy with anti-interleukin-2 receptor antibodies.',\n",
       " 'paraphrases': ['Autologous stem cell transplant has worse graft function than induction therapy with anti-interleukin-2 receptor antibodies.',\n",
       "  'Autologous transplantation of mesenchymal stem cells has worse graft function than induction therapy with anti-Il-A receptor antibodies.',\n",
       "  'Autologous transplantation of mesenchymal stem cells has worse graft function than the induction therapy with anti-interleukin-2 receptor antibodies.',\n",
       "  'Autologous stem cells transplanting have worse graft function than Induction Therapy with anti-interleukin-2 receptor antibodies.',\n",
       "  'Autologous transplantation of mesenchymal stem cells has a worse graft function than induction therapy with anti-Interleukin-2 receptor antibodies.',\n",
       "  'Autologous mesenchymal stem cell transplant has worse graft function than induction therapy with anti-interleukin-2 receptor-antigens']}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paraphrase_claims[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015916824340820312,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 50,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381ac40d8b8f490ebc5b709a9df84170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/50.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016526222229003906,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 1321,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dabb33f49794c9b976981bd28a971da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015444040298461914,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 898822,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d2f366b0d44192b01d096a922073cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016028404235839844,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 456318,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b888d8f6a6af441d8470010eb58b076b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016689300537109375,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 47,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a839bee8b8c41669fcebc020d21de9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/47.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01360177993774414,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 214,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1204f68cb2e46738239b5d696284096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/214 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011681079864501953,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 1625577455,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2fc7e8733b14a5a9a8a31e3f1d0e7de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.51G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"stanford-oval/paraphraser-bart-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"stanford-oval/paraphraser-bart-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        outputs = model.generate(\n",
    "            input_ids=input_ids, attention_mask=attention_masks,\n",
    "            max_length=PARAPHRASE_PROJECT_SETTINGS['paraphrase_model']['t5_paraphrase_model_params']['max_length'],\n",
    "            do_sample=PARAPHRASE_PROJECT_SETTINGS['paraphrase_model']['t5_paraphrase_model_params']['do_sample'],\n",
    "            top_k=PARAPHRASE_PROJECT_SETTINGS['paraphrase_model']['t5_paraphrase_model_params']['top_k'],\n",
    "            top_p=PARAPHRASE_PROJECT_SETTINGS['paraphrase_model']['t5_paraphrase_model_params']['top_p'],\n",
    "            repetition_penalty=PARAPHRASE_PROJECT_SETTINGS['paraphrase_model']['t5_paraphrase_model_params']['repetition_penalty'],\n",
    "            early_stopping=PARAPHRASE_PROJECT_SETTINGS['paraphrase_model']['t5_paraphrase_model_params']['early_stopping'],\n",
    "            num_return_sequences=PARAPHRASE_PROJECT_SETTINGS['paraphrase_model']['t5_paraphrase_model_params']['num_return_sequences']\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.026522159576416016,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 999,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b853025b9140bb8a2fc9ba461c5fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/999 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015060186386108398,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 6247,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8529e39fdd734be985e79582e4add245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/6.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013937950134277344,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading",
       "rate": null,
       "total": 39799,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4913681142e4412aade3b352f7b61338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/38.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'add_code_sample_docstrings' from 'transformers.utils' (/home/qudratealahyratu/anaconda3/envs/scifact/lib/python3.7/site-packages/transformers/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13348/3269488753.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load model directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"THUDM/WebGLM\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/scifact/lib/python3.7/site-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mmodule_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             model_class = get_class_from_dynamic_module(\n\u001b[0;32m--> 442\u001b[0;31m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_file\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".py\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m             )\n\u001b[1;32m    444\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/scifact/lib/python3.7/site-packages/transformers/dynamic_module_utils.py\u001b[0m in \u001b[0;36mget_class_from_dynamic_module\u001b[0;34m(pretrained_model_name_or_path, module_file, class_name, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, **kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     )\n\u001b[0;32m--> 378\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_class_in_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".py\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/scifact/lib/python3.7/site-packages/transformers/dynamic_module_utils.py\u001b[0m in \u001b[0;36mget_class_in_module\u001b[0;34m(class_name, module_path)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \"\"\"\n\u001b[1;32m    147\u001b[0m     \u001b[0mmodule_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/scifact/lib/python3.7/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/scifact/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/scifact/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/scifact/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/scifact/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/scifact/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/scifact/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m~/.cache/huggingface/modules/transformers_modules/THUDM/WebGLM/ca0ffbd2f4eb3fabfcdc28eed4a40457f5a4fb14/modeling_glm.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgelu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m from transformers.utils import (\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0madd_code_sample_docstrings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0madd_start_docstrings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'add_code_sample_docstrings' from 'transformers.utils' (/home/qudratealahyratu/anaconda3/envs/scifact/lib/python3.7/site-packages/transformers/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"THUDM/WebGLM\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scifact",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
