{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module_path :  /home/qudratealahyratu/research/nlp/fact_checking/my_work/T5ParEvo\n",
      "root dir :  /home/qudratealahyratu/research/nlp/fact_checking/my_work/T5ParEvo\n",
      "definitions.PROJECT_VARS.ROOT_DIR :  /home/qudratealahyratu/research/nlp/fact_checking/my_work/T5ParEvo\n",
      "os.path.dirname(definitions.PROJECT_VARS.ROOT_DIR) :  /home/qudratealahyratu/research/nlp/fact_checking/my_work\n",
      "/home/qudratealahyratu/research/nlp/fact_checking/my_work/T5ParEvo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qudratealahyratu/anaconda3/envs/scifact/lib/python3.7/site-packages/pytorch_lightning/core/decorators.py:66: LightningDeprecationWarning: The `@auto_move_data` decorator is deprecated in v1.3 and will be removed in v1.5. Please use `trainer.predict` instead for inference. The decorator was applied to `predict`\n",
      "  \"The `@auto_move_data` decorator is deprecated in v1.3 and will be removed in v1.5.\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List,Tuple, Optional\n",
    "import json\n",
    "#\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(0,module_path)\n",
    "print('module_path : ', module_path)\n",
    "from config import SciFactT5Config\n",
    "import definitions\n",
    "sys.path.append(os.path.dirname(definitions.PROJECT_VARS.ROOT_DIR))\n",
    "print('definitions.PROJECT_VARS.ROOT_DIR : ', definitions.PROJECT_VARS.ROOT_DIR)\n",
    "print('os.path.dirname(definitions.PROJECT_VARS.ROOT_DIR) : ',os.path.dirname(definitions.PROJECT_VARS.ROOT_DIR))\n",
    "#\n",
    "\n",
    "from T5ParEvo.src.data.data import Claim, Label, ClaimPredictions,GoldDataset\n",
    "from T5ParEvo.src.linguistic.ner_abbr import NEREntity, Abbreviation\n",
    "from multivers import util\n",
    "from multivers.data_r import ClaimDataLoaderGenerator, get_dataloader, DataLoaderGenerator\n",
    "from multivers.model_r import MultiVerSModel\n",
    "\n",
    "from T5ParEvo.target_system.multivers.multivers_interface import PredictionParams, ModelPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset to be used only for training\n",
    "cfg= SciFactT5Config()\n",
    "ds_train = GoldDataset(cfg.target_dataset.loc_target_dataset_corpus,\n",
    "                    cfg.target_dataset.loc_target_dataset_train)\n",
    "claim_train = ds_train.get_claim(39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = PredictionParams(\n",
    "    checkpoint_path= \"/home/qudratealahyratu/research/nlp/fact_checking/my_work/multivers/checkpoints/scifact.ckpt\",\n",
    "    output_file= None,#\"prediction/pred_opt_scifact.jsonl\",\n",
    "    batch_size=5,\n",
    "    device=0,\n",
    "    num_workers=4,\n",
    "    no_nei=False,\n",
    "    force_rationale=False,\n",
    "    debug=False,\n",
    ")\n",
    "corpus_file = cfg.target_dataset.loc_target_dataset_corpus#cfg.target_dataset.loc_target_dataset_test#\"/home/qudratealahyratu/research/nlp/fact_checking/my_work/multivers/data/scifact/corpus.jsonl\"\n",
    "\n",
    "gold_claims = Claim.load_claims_from_file(cfg.target_dataset.loc_target_dataset_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-large-4096 were not used when initializing LongformerModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing LongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/qudratealahyratu/anaconda3/envs/scifact/lib/python3.7/site-packages/deprecate/deprecation.py:115: LightningDeprecationWarning: The `Metric` was deprecated since v1.3.0 in favor of `torchmetrics.metric.Metric`. It will be removed in v1.5.0.\n",
      "  stream(template_mgs % msg_args)\n",
      "100%|██████████| 594/594 [05:03<00:00,  1.96it/s]\n"
     ]
    }
   ],
   "source": [
    "#get unique claims\n",
    "unique_gold_claims = Claim.get_unique_claims(gold_claims)\n",
    "# Predict for unique claims\n",
    "dataloader_generator = DataLoaderGenerator(params, unique_gold_claims, corpus_file)\n",
    "dataloader = dataloader_generator.get_dataloader_by_claims()\n",
    "predictor = ModelPredictor(params, dataloader)\n",
    "prediction_formatted = predictor.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Formatting predictions: 100%|██████████| 297/297 [00:00<00:00, 50060.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# prediction_formatted\n",
    "claim_org_predictions: List[ClaimPredictions] = []\n",
    "# format all the predictions\n",
    "for cur_prediction in tqdm(prediction_formatted, desc=\"Formatting predictions\"):\n",
    "    cur_claim = Claim.get_claim_by_id(gold_claims, cur_prediction['id'])\n",
    "    claim_predictions = ClaimPredictions.from_formatted_prediction(cur_prediction, gold_claim = cur_claim)\n",
    "    claim_org_predictions.append(claim_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Example 7: 10-20% of people with severe mental disorder receive no treatment in low and middle income countries."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claim_org_predictions[0].gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "par_claim_1 = copy.deepcopy(claim_org_predictions[0])\n",
    "par_claim_1.gold.claim = '10-20 percent of people with high mental disorder receive no treatment in low and middle income countries.'\n",
    "\n",
    "# from T5ParEvo.src.data.data import Claim, Label, ClaimPredictions,GoldDataset,ParaphrasedClaim\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/qudratealahyratu/.cache/torch/hub/pytorch_fairseq_main\n",
      "2023-06-24 22:52:16 | INFO | fairseq.file_utils | loading archive file http://dl.fbaipublicfiles.com/fairseq/models/roberta.large.mnli.tar.gz from cache at /home/qudratealahyratu/.cache/torch/pytorch_fairseq/7685ba8546f9a5ce1a00c7a6d7d44f7e748d22681172f0f391c3d48f487c801c.74e37d47306b3cc51c5f8d335022a392c29f1906c8cd9e9cd3446d7422cf55d8\n",
      "/home/qudratealahyratu/anaconda3/envs/scifact/lib/python3.7/site-packages/hydra/experimental/initialize.py:43: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
      "  deprecation_warning(message=message)\n",
      "/home/qudratealahyratu/anaconda3/envs/scifact/lib/python3.7/site-packages/hydra/experimental/initialize.py:48: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  caller_stack_depth=caller_stack_depth + 1,\n",
      "/home/qudratealahyratu/anaconda3/envs/scifact/lib/python3.7/site-packages/hydra/experimental/compose.py:25: UserWarning: hydra.experimental.compose() is no longer experimental. Use hydra.compose()\n",
      "  deprecation_warning(message=message)\n",
      "/home/qudratealahyratu/anaconda3/envs/scifact/lib/python3.7/site-packages/hydra/core/default_element.py:128: UserWarning: In 'config': Usage of deprecated keyword in package header '# @package _group_'.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/changes_to_package_header for more information\n",
      "  See {url} for more information\"\"\"\n",
      "/home/qudratealahyratu/.cache/torch/hub/pytorch_fairseq_main/fairseq/checkpoint_utils.py:419: UserWarning: \n",
      "'config' is validated against ConfigStore schema with the same name.\n",
      "This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.\n",
      "  state = load_checkpoint_to_cpu(filename, arg_overrides)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANTLR runtime and generated code versions disagree: 4.9.3!=4.8\n",
      "ANTLR runtime and generated code versions disagree: 4.9.3!=4.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qudratealahyratu/anaconda3/envs/scifact/lib/python3.7/site-packages/hydra/compose.py:57: UserWarning: \n",
      "The strict flag in the compose API is deprecated.\n",
      "See https://hydra.cc/docs/upgrades/0.11_to_1.0/strict_mode_flag_deprecated for more info.\n",
      "\n",
      "  \"\"\"\n",
      "/home/qudratealahyratu/anaconda3/envs/scifact/lib/python3.7/site-packages/hydra/experimental/initialize.py:43: UserWarning: hydra.experimental.initialize() is no longer experimental. Use hydra.initialize()\n",
      "  deprecation_warning(message=message)\n",
      "/home/qudratealahyratu/anaconda3/envs/scifact/lib/python3.7/site-packages/hydra/experimental/initialize.py:48: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  caller_stack_depth=caller_stack_depth + 1,\n",
      "/home/qudratealahyratu/.cache/torch/hub/pytorch_fairseq_main/fairseq/models/roberta/model.py:325: UserWarning: \n",
      "'config' is validated against ConfigStore schema with the same name.\n",
      "This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.\n",
      "  **kwargs,\n",
      "2023-06-24 22:52:20 | INFO | fairseq.tasks.masked_lm | dictionary: 50264 types\n",
      "2023-06-24 22:52:32 | INFO | fairseq.models.roberta.model | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 8, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'no_c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': True, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 3, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': 'cached', 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': True, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': True, 'no_save_optimizer_state': True, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 10, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='roberta_large', activation_dropout=0.0, activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_input=False, arch='roberta_large', attention_dropout=0.1, bagging=False, best_checkpoint_metric='accuracy', bpe='gpt2', bucket_cap_mb=25, clip_norm=0.0, cpu=False, criterion='masked_lm', curriculum=0, data='/home/qudratealahyratu/.cache/torch/pytorch_fairseq/7685ba8546f9a5ce1a00c7a6d7d44f7e748d22681172f0f391c3d48f487c801c.74e37d47306b3cc51c5f8d335022a392c29f1906c8cd9e9cd3446d7422cf55d8', dataset_impl='cached', ddp_backend='no_c10d', debug=False, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.1, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=24, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, end_learning_rate=0.0, ffn_reg_scale_factor=0.0, find_unused_parameters=False, fix_batches_to_gpus=False, force_anneal=None, fp16=True, fp16_init_scale=4, fp16_scale_tolerance=0.0, fp16_scale_window=128, global_sync_iter=10, init_token=0, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.0, layernorm_embedding=True, load_checkpoint_heads=True, log_format='json', log_interval=100, lr=[1e-05], lr_scheduler='polynomial_decay', max_epoch=10, max_positions=512, max_sentences=32, max_sentences_valid=32, max_source_positions=512, max_target_positions=512, max_tokens=4400, max_update=0, maximize_best_checkpoint_metric=True, memory_efficient_fp16=False, mha_reg_scale_factor=0.0, min_loss_scale=0.0001, min_params_to_wrap=100000000, no_epoch_checkpoints=True, no_last_checkpoints=True, no_progress_bar=False, no_save=False, no_save_optimizer_state=True, no_scale_embedding=True, no_shuffle=False, no_token_positional_embeddings=False, num_classes=3, num_workers=3, optimizer='adam', optimizer_overrides='{}', pooler_activation_fn='tanh', pooler_dropout=0.3, power=1.0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, regression_target=False, remove_head=True, remove_sentence_classification_head=True, required_batch_size_multiple=1, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, restore_file='checkpoint_last.pt', save_interval=1, save_interval_updates=0, save_predictions=None, seed=8, sentence_avg=False, separator_token=2, skip_invalid_size_inputs_valid_test=False, spectral_norm_classification_head=False, stop_min_lr=-1, task='masked_lm', tbmf_wrapper=False, threshold_loss_scale=1.0, tokenizer=None, tokens_per_sample=512, total_num_update=123873, train_subset='train', truncate_sequence=False, untie_weights_roberta=False, update_freq=[1], use_bmuf=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_updates=30968, weight_decay=0.1), 'task': {'_name': 'masked_lm', 'data': '/home/qudratealahyratu/.cache/torch/pytorch_fairseq/7685ba8546f9a5ce1a00c7a6d7d44f7e748d22681172f0f391c3d48f487c801c.74e37d47306b3cc51c5f8d335022a392c29f1906c8cd9e9cd3446d7422cf55d8', 'sample_break_mode': 'none', 'tokens_per_sample': 512, 'mask_prob': 0.15, 'leave_unmasked_prob': 0.1, 'random_token_prob': 0.1, 'freq_weighted_replacement': False, 'mask_whole_words': False, 'mask_multiple_length': 1, 'mask_stdev': 0.0, 'shorten_method': 'none', 'shorten_data_split_list': '', 'seed': 8}, 'criterion': {'_name': 'masked_lm', 'tpu': True}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': True, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 30968, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 123873.0, 'lr': [1e-05]}, 'scoring': None, 'bpe': {'_name': 'gpt2', 'gpt2_encoder_json': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', 'gpt2_vocab_bpe': 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'}, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}\n"
     ]
    }
   ],
   "source": [
    "# Assuming cfg is your OmegaConf object\n",
    "# from T5ParEvo.src.linguistic.entailment import NliLabels, EntailmentModel#, EntailmentChecker\n",
    "from T5ParEvo.src.data.data import Claim, ParaphrasedClaim\n",
    "import torch\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class NliLabels(Enum):\n",
    "    CONTRADICTION = 0\n",
    "    NEUTRAL = 1\n",
    "    ENTAILMENT = 2\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.name\n",
    "    @property\n",
    "    def description(self):\n",
    "        descriptions = {\n",
    "            \"CONTRADICTION\": \"The sentences have opposing meanings.\",\n",
    "            \"NEUTRAL\": \"The sentences are not related in any specific way.\",\n",
    "            \"ENTAILMENT\": \"The sentences have the same meaning or one implies the other.\"\n",
    "        }\n",
    "        return descriptions[self.name]\n",
    "    \n",
    "    @classmethod\n",
    "    def from_string(cls, label_name):\n",
    "        return cls[label_name.upper()]\n",
    "    \n",
    "@dataclass \n",
    "class EntailmentModel:\n",
    "    model_repo : str = 'pytorch/fairseq'\n",
    "    model_name : str = 'roberta.large.mnli'    \n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EntailmentChecker:\n",
    "    model: torch.nn.Module = field(init=False)\n",
    "    model_config: EntailmentModel = field(default=EntailmentModel())\n",
    "    label_mapping: Dict[int, NliLabels] = field(default_factory=lambda: {0: NliLabels.CONTRADICTION, 1: NliLabels.NEUTRAL, 2: NliLabels.ENTAILMENT})\n",
    "    device: str = field(default='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.model = self._load_model()\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def _load_model(self) -> torch.nn.Module:\n",
    "        return torch.hub.load(self.model_config.model_repo, self.model_config.model_name)\n",
    "\n",
    "    def check_entailment_by_paraphrased_claim(self, paraphrased_claim: ParaphrasedClaim) -> None:\n",
    "        labels_org_gen = self._get_labels(paraphrased_claim.original_claim.claim, paraphrased_claim.paraphrased_claim.claim)\n",
    "        labels_gen_org = self._get_labels(paraphrased_claim.paraphrased_claim.claim, paraphrased_claim.original_claim.claim)\n",
    "\n",
    "        paraphrased_claim.nli_label = labels_org_gen[1] if labels_org_gen[1] == labels_gen_org[1] else None\n",
    "\n",
    "    def check_entailment_by_claims(self, original_claim: Claim, paraphrased_claim: Claim) -> Dict[str, Union[NliLabels, float]]:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            original_claim (Claim): _description_\n",
    "            paraphrased_claim (Claim): _description_\n",
    "\n",
    "        Returns:\n",
    "            Dict[str, Union[NliLabels, float]]: return {'nli_label_org_gen' : x[1], 'nli_label_gen_org': y[1], 'nli_val_org_gen': x[0] , 'nli_val_gen_org': y[0]}\n",
    "        \"\"\"\n",
    "        labels_org_gen = self._get_labels(original_claim.claim, paraphrased_claim.claim)\n",
    "        labels_gen_org = self._get_labels(paraphrased_claim.claim, original_claim.claim)\n",
    "        # print(labels_org_gen, labels_gen_org)\n",
    "\n",
    "        return {'nli_label_org_gen' : labels_org_gen[1], 'nli_label_gen_org': labels_gen_org[1], 'nli_val_org_gen': labels_org_gen[0] , 'nli_val_gen_org': labels_gen_org[0]}\n",
    "        # paraphrased_claim.nli_label = labels_org_gen[1] if labels_org_gen[1] == labels_gen_org[1] else None\n",
    "        # return paraphrased_claim\n",
    "\n",
    "    def print_label_mapping(self):\n",
    "        for key, value in self.label_mapping.items():\n",
    "            print(f'{key}: {value.name}')\n",
    "\n",
    "    def _get_labels(self, sentence1: str, sentence2: str) -> List[Union[int, NliLabels]]:\n",
    "        tokens_sentences = self.model.encode(sentence1, sentence2)\n",
    "        logprobs_sentences = self.model.predict('mnli', tokens_sentences)\n",
    "        cal_val_mlnli = logprobs_sentences.argmax(dim=1).item()\n",
    "        # print(cal_val_mlnli)\n",
    "        cal_label_mlnli = self.label_mapping[cal_val_mlnli]\n",
    "\n",
    "        return [cal_val_mlnli, cal_label_mlnli]\n",
    "\n",
    "checker = EntailmentChecker()\n",
    "# checker.print_label_mapping()\n",
    "# print(checker.label_mapping)\n",
    "\n",
    "# For a given original claim and generated claim\n",
    "\n",
    "# You can get the entailment label\n",
    "entailment_labels = checker.check_entailment_by_claims(original_claim =  claim_org_predictions[0].gold, paraphrased_claim = par_claim_1.gold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nli_label_org_gen': ENTAILMENT,\n",
       " 'nli_label_gen_org': ENTAILMENT,\n",
       " 'nli_val_org_gen': 2,\n",
       " 'nli_val_gen_org': 2}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entailment_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scifact",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
